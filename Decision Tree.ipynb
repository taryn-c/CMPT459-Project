{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing import *;\n",
    "from sklearn.model_selection import StratifiedKFold,KFold,train_test_split;\n",
    "from sklearn.preprocessing import LabelEncoder;\n",
    "from sklearn.tree import DecisionTreeClassifier;\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report;\n",
    "from skfeature.function.similarity_based import fisher_score;\n",
    "from skfeature.function.statistical_based import gini_index;\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Selection\n",
    "\n",
    "Since the building_id, listing_id, and manager_id are neither categorical or numeric data, it really isn't relevant for our model. We will remove these attributes. We will also remove the photos column because we won't be using this in our model either. We will also remove street_address because we can use the display_address as a categorical value since this is just the genral street that the listing is on. This helps identify the general neighbourhood the listing is in for the buyer. The description, created, and features columns are removed because these are represented by newly extracted feature columns from the previous milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['photos','listing_id','building_id','manager_id','street_address','features','description','created'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"interest_level\"] = data[\"interest_level\"].astype('category')\n",
    "data[\"target\"] = data[\"interest_level\"].cat.codes\n",
    "data.drop(['interest_level'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"address\"] = data[\"display_address\"].astype('category')\n",
    "data[\"address\"] = data[\"address\"].cat.codes\n",
    "data.drop(['display_address'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split our data\n",
    "\n",
    "I will split our input and target variables into X and y respectively. I do this before feature selection to reduce bias by keeping the test data untouched. In this way, the test data doesn't affect our selection methods. Next, we will check the distribution of our target variable to see if we must stratify our training and testing data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "int_level = train_df['interest_level'].value_counts()\n",
    "plt.figure(figsize=(15,6))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=1, order=['low','medium','high'],color=color[0])\n",
    "plt.ylabel('Number of Occurrences', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Interest level', fontsize=14, fontweight='bold')\n",
    "plt.title('Target distribution', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the distribution is skewed, we should stratify our data when spliting so it represents our data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y)\n",
    "X_train.reset_index(inplace=True);\n",
    "X_test.reset_index(inplace=True);\n",
    "y_train.reset_index();\n",
    "y_test.reset_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher score\n",
    "\n",
    "Since this is only valid for numerica features, we must first take a subset of our data. We will separate the data based on interest level to calculate the mean and standard deviation of each class. These values will be used to calculate the fisher score for each feature. We can then use a filtering technique to find the most relevant features based on the scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take subset\n",
    "numeric = ['bathrooms','bedrooms','latitude','longitude','price','hour_created','address']\n",
    "num_data = data[['bathrooms','bedrooms','latitude','longitude','price','hour_created','address','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data by interest level\n",
    "high = num_data[num_data['target'] == 2].drop(['target'], axis=1)\n",
    "med = num_data[num_data['target'] == 1].drop(['target'], axis=1)\n",
    "low = num_data[num_data['target'] == 0].drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean of each feature in each class\n",
    "avg_if = np.array([high.mean(),\n",
    "      med.mean(),\n",
    "      low.mean()])\n",
    "#calculate mean of each feature\n",
    "avg_f = np.array(num_data.drop(['target'], axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate variance for each feature\n",
    "var = np.square(np.array([high.std(),\n",
    "      med.std(),\n",
    "      low.std()]))\n",
    "\n",
    "# calculate probability of each class\n",
    "prob = np.array([high.shape[0]/float(data.shape[0]),\n",
    "             med.shape[0]/float(data.shape[0]),\n",
    "             low.shape[0]/float(data.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.3159763636589696e-10,\n",
       " 3.5701864052593236e-10,\n",
       " 2.381635477575132e-10,\n",
       " 1.7865112839818668e-10,\n",
       " 0.001923534630954183,\n",
       " 0.0016029606550212914,\n",
       " 0.00274435114891092]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher = []\n",
    "numerator = []\n",
    "denomerator = []\n",
    "\n",
    "for feat in np.arange(0,avg_if.shape[1]):\n",
    "    for class_i in np.arange(0,avg_if.shape[0]):\n",
    "        numerator.append(np.array(prob[class_i]*np.square(avg_if[class_i][feat]-avg_f[feat])))\n",
    "        denomerator.append(np.array(prob[class_i]*var[class_i]))      \n",
    "    fisher.append(np.array(numerator).sum()/np.array(denomerator).sum())\n",
    "fisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the fisher scores, it looks like the address, price, and hour the listing was created have the best fisher score, in that order. The worst was longitude and the rest weren't that far off either with 10 significant digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Version\n",
    "\n",
    "The classifier doesn't accept the extracted text features from the previous milestone so for the first classifier they were removed and the classifier was trained for the numerical data only. The 3 features with the highest fisher scores are selected for the first classifier. These are price, hour created, and bedrooms. The default Gini index was used to determine the best split for each node. The classifier predicted with average 61.35% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6089234677675452,\n",
       " 0.6143220069863449,\n",
       " 0.6105112734201333,\n",
       " 0.6156900111164046,\n",
       " 0.6180720978243608]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation for first set of classifiers\n",
    "acc_scores = []\n",
    "top3 = ['price', 'hour_created', 'address']\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    # split data\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    # Create classifier object\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=0)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(np.array(X_train[top3]),np.array(y_train),check_input=False)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_valid[top3])\n",
    "    acc_scores.append(accuracy_score(y_valid, y_pred))\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6135037714229578"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(acc_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Version\n",
    "\n",
    "All numeric features were used for this classifier. Gini index was used to determine the best split for each node. The classifier predicted with average 64.30% accuracy. It looks like the classifier has slightly better accuracy with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6439769795594364,\n",
       " 0.6353711790393013,\n",
       " 0.6399364827312426,\n",
       " 0.6419213973799127,\n",
       " 0.6536323938070663]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation for first set of classifiers\n",
    "acc_scores = []\n",
    "for train_index, valid_index in kf.split(X_train):\n",
    "    # split data\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    # Create classifier object\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=0)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(np.array(X_train[numeric]),np.array(y_train),check_input=False)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_valid[numeric])\n",
    "    acc_scores.append(accuracy_score(y_valid, y_pred))\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6429676865033919"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(acc_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Version\n",
    "\n",
    "All numeric features were used for this classifier. Gini index was used to determine the best split for each node. A stratified k-fold cross validation method was used. The classifier predicted with average 64.89% accuracy, which is ever so slightly better than regular k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6472754985393115,\n",
       " 0.6386383843515814,\n",
       " 0.650870283318511,\n",
       " 0.6525219158937873,\n",
       " 0.655146124523507]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation for first set of classifiers\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "acc_scores = []\n",
    "for train_index, valid_index in kf.split(X_train, y_train):\n",
    "    # split data\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    # Create classifier object\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", random_state=0)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(np.array(X_train[numeric]),np.array(y_train),check_input=False)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_valid[numeric])\n",
    "    acc_scores.append(accuracy_score(y_valid, y_pred))\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6488904413253396"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(acc_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth\n",
    "\n",
    "All numeric features were used for this classifier. Entropy was used to determine the best split for each node. A stratified k-fold cross validation method was used. The classifier predicted with average 64.28% accuracy, which is ever so slightly worse than regular k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6423611111111112,\n",
       " 0.6427685437856612,\n",
       " 0.6431761786600496,\n",
       " 0.6387096774193548,\n",
       " 0.6471464019851116]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation for first set of classifiers\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "acc_scores = []\n",
    "for train_index, valid_index in kf.split(X_train, y_train):\n",
    "    # split data\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    # Create classifier object\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(np.array(X_train[numeric]),np.array(y_train),check_input=False)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_valid[numeric])\n",
    "    acc_scores.append(accuracy_score(y_valid, y_pred))\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428323825922576"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(acc_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Version\n",
    "\n",
    "All numeric features were used for this classifier. Gini was used to determine the best split for each node. A stratified k-fold cross validation method was used. Minimum support was changed to 3 to combat overfitting. The classifier predicted with average 64.28% accuracy, which is ever so slightly worse than regular k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6479702510071274,\n",
       " 0.6476426799007444,\n",
       " 0.6349255583126551,\n",
       " 0.6488833746898263,\n",
       " 0.6451612903225806]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform cross-validation for first set of classifiers\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "acc_scores = []\n",
    "for train_index, valid_index in kf.split(X_train, y_train):\n",
    "    # split data\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    # Create classifier object\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=0,min_samples_leaf=3)\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(np.array(X_train[numeric]),np.array(y_train),check_input=False)\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_valid[numeric])\n",
    "    acc_scores.append(accuracy_score(y_valid, y_pred))\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6449166308465868"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(acc_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hot encode text features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24914675767918087, 0.7908096280087528, 0.30959752321981426]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_valid, y_pred)\n",
    "precision = []\n",
    "recall = []\n",
    "for i in range(0,len(conf_matrix)):\n",
    "    precision.append(conf_matrix[i][i]/float(conf_matrix[:,i].sum()))\n",
    "    recall.append(conf_matrix[i][i]/float(conf_matrix[i,:].sum()))\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         low       0.25      0.31      0.28       234\n",
      "      medium       0.79      0.79      0.79      2285\n",
      "        high       0.31      0.28      0.30       705\n",
      "\n",
      "   micro avg       0.65      0.65      0.65      3224\n",
      "   macro avg       0.45      0.46      0.45      3224\n",
      "weighted avg       0.65      0.65      0.65      3224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred, target_names=['low', 'medium','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class log loss output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test output for log loss\n",
    "y_prob = clf.predict_proba(X_test[numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
